{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5GNGeRjp1kZX5C31zFU21",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataemperor/Shrimple/blob/chanmini/shrimp_demand_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# File paths for uploaded .txt files in Colab\n",
        "file_paths = {\n",
        "    \"Q1\": \"/content/Q1.txt\",\n",
        "    \"Q2\": \"/content/Q2.txt\",\n",
        "    \"Q3\": \"/content/Q3.txt\",\n",
        "      \"Q4\": \"/content/Q4.txt\"}"
      ],
      "metadata": {
        "id": "LWbFQxEItkbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load a text file\n",
        "def load_txt(file_path, quarter):\n",
        "    df = pd.read_csv(file_path, sep=\"\\t\", engine=\"python\")  # Tab-separated data\n",
        "    df = df.melt(var_name=\"year\", value_name=\"demand\")  # Convert wide format to long format\n",
        "    df[\"year\"] = df[\"year\"].str.extract('(\\d{4})').astype(int)  # Extract the first year\n",
        "    df[\"quarter\"] = quarter  # Add quarter column\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "f9HvbYI0u4M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and merge all data\n",
        "dataframes = [load_txt(file_paths[q], i) for i, q in enumerate([\"Q1\", \"Q2\", \"Q3\", \"Q4\"], start=1)]\n",
        "data = pd.concat(dataframes, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "POReEKG2vZQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert to datetime format\n",
        "data[\"date\"] = pd.to_datetime(data[\"year\"].astype(str) + \"Q\" + data[\"quarter\"].astype(str))\n",
        "data = data.sort_values(by=\"date\").reset_index(drop=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djl_dNY-vj4t",
        "outputId": "30ccc9bc-3151-4fe2-9981-785e1cbbdcf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3e1f80ddb26c>:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data[\"date\"] = pd.to_datetime(data[\"year\"].astype(str) + \"Q\" + data[\"quarter\"].astype(str))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Handle missing values\n",
        "data[\"demand\"] = pd.to_numeric(data[\"demand\"], errors='coerce')  # Convert demand to numeric\n",
        "data.fillna(method='ffill', inplace=True)  # Forward fill missing values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGZQScLvvlIW",
        "outputId": "48f80f68-3e5c-48e2-ebb3-b564e1783e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-1e6139106f11>:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data.fillna(method='ffill', inplace=True)  # Forward fill missing values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Feature Engineering\n",
        "data[\"lag_1\"] = data[\"demand\"].shift(1)  # Previous quarter demand\n",
        "data[\"lag_2\"] = data[\"demand\"].shift(2)  # Two quarters ago\n",
        "data[\"rolling_mean\"] = data[\"demand\"].rolling(window=4).mean()  # Average over 4 quarters\n"
      ],
      "metadata": {
        "id": "KQ2F0uzLvqxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop missing values (after shift operations)\n",
        "data.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "VrRMUZ88vrwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Assuming 'lag_1', 'lag_2', and 'rolling_mean' are your features\n",
        "X = data[['lag_1', 'lag_2', 'rolling_mean']]\n",
        "y = data['demand']\n",
        "\n",
        "# Apply scaling to features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the scaled data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n"
      ],
      "metadata": {
        "id": "EAotygdm1rnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define a larger hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 500],  # Number of trees\n",
        "    'max_depth': [10, 20, 30, 50, None],    # Depth of the tree\n",
        "    'min_samples_split': [2, 5, 10, 20],    # Minimum samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4, 10],      # Minimum samples required at leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider for split\n",
        "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
        "}\n",
        "\n",
        "# Initialize the RandomForestRegressor\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Display best parameters\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "# Use the best model to train\n",
        "model = grid_search.best_estimator_\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WMYGu6dvv_V",
        "outputId": "86c974ef-b605-4c24-bd8f-67c6ee039831"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1920 candidates, totalling 9600 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# Initialize TimeSeriesSplit for cross-validation\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Train the model using cross-validation\n",
        "scores = []\n",
        "for train_index, test_index in tscv.split(X_train):\n",
        "    X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
        "    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    model.fit(X_train_cv, y_train_cv)\n",
        "    y_pred_cv = model.predict(X_test_cv)\n",
        "    mse_cv = mean_squared_error(y_test_cv, y_pred_cv)\n",
        "    scores.append(mse_cv)\n",
        "\n",
        "# Print average cross-validation score\n",
        "print(f\"Average MSE from Cross-Validation: {np.mean(scores)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6GWXXHqkvs9T",
        "outputId": "53b3506c-393f-46e4-fb54-0bb18f3a39f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-356c82286a3f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0my_pred_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmse_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Select important features based on feature importance\n",
        "sfm = SelectFromModel(model, threshold=0.05)  # 0.05 means keep features with importance greater than 5%\n",
        "sfm.fit(X_train, y_train)\n",
        "\n",
        "# Transform the data to select important features\n",
        "X_train_selected = sfm.transform(X_train)\n",
        "X_test_selected = sfm.transform(X_test)\n"
      ],
      "metadata": {
        "id": "Wj9wfeiN18sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make Predictions\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "wKDAUwc-vxXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate Model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArZ666tRvyTl",
        "outputId": "348fb240-160d-402f-9fb6-aaf898eae15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 38429.647329628315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Future Predictions (Next 4 Quarters)\n",
        "future_year = data[\"year\"].max() + 1\n",
        "future_quarters = [1, 2, 3, 4]\n",
        "future_data = pd.DataFrame({\"year\": [future_year] * 4, \"quarter\": future_quarters})\n"
      ],
      "metadata": {
        "id": "ML-I9-JcvzRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate lag values from the last known data point\n",
        "latest_values = data.iloc[-1]\n",
        "future_data[\"lag_1\"] = [latest_values[\"demand\"]] + [np.nan] * 3\n",
        "future_data[\"lag_2\"] = [latest_values[\"lag_1\"]] + [latest_values[\"demand\"]] + [np.nan] * 2\n",
        "future_data[\"rolling_mean\"] = latest_values[\"rolling_mean\"]\n"
      ],
      "metadata": {
        "id": "RCqDlad0v0Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predict Future Demand\n",
        "future_data.fillna(method=\"ffill\", inplace=True)  # Fill missing lag values\n",
        "future_data[\"forecast\"] = model.predict(future_data[features])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4IFiIflv1V1",
        "outputId": "23918a20-38a0-4fe2-fa45-6410433a8c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-1be25d43e209>:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  future_data.fillna(method=\"ffill\", inplace=True)  # Fill missing lag values\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display Forecast\n",
        "print(\"\\nFuture Demand Forecast:\")\n",
        "print(future_data[[\"year\", \"quarter\", \"forecast\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl_LSOK9v2Yn",
        "outputId": "9bb88b16-def8-4834-ff67-282bed1efc1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Future Demand Forecast:\n",
            "   year  quarter     forecast\n",
            "0  2023        1  1375.565846\n",
            "1  2023        2  1375.565846\n",
            "2  2023        3  1375.565846\n",
            "3  2023        4  1375.565846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot Results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(data[\"date\"], data[\"demand\"], label=\"Actual Demand\")\n",
        "plt.plot(pd.date_range(start=data[\"date\"].max(), periods=5, freq='Q')[1:], future_data[\"forecast\"], label=\"Forecast\", linestyle=\"dashed\", color=\"red\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Shrimp Demand\")\n",
        "plt.title(\"Shrimp Demand Forecasting\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kYlc8j75v3V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Calculate Evaluation Metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print Accuracy Results\n",
        "print(f\"📊 Model Performance Metrics:\")\n",
        "print(f\"✅ Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"✅ Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"✅ Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"✅ R² Score: {r2:.2f} (Closer to 1 means better model fit)\")\n"
      ],
      "metadata": {
        "id": "hvbIOg4Qt7mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ej8FdoQ6t7Q0"
      }
    }
  ]
}